hydra:
  run:
    dir: ./outputs/${wandb.name}/${now:%Y-%m-%d_%H-%M-%S}

defaults:
  - _self_
  - tokenizer: default
  - world_model: default
  - actor_critic: default
  - env: default
  - datasets: default

env_actions: '{"num_actions": 256, "num_continuous": 3}'  # module train_cloud argparse workaround

wandb:
  mode: online
  project: iris
  entity: null
  name: "fused_gen"
  group: null
  tags: []
  notes: "finetune with 2 gen heads"

initialization:
  storage_prefix: "" # run prefix on bucket to load agent weights. Prioritized over path
  path_to_checkpoint: null #C:\Users\Mykhailo_Tkachuk\PycharmProjects\Brawl-Stars-AI\outputs\2023-08-27\09-17-56\checkpoints\last.pt
  load_tokenizer: False
  load_world_model: False
  load_actor_critic: True

common:
  epochs: 600
  device: "cuda:0"
  do_checkpoint: True
  seed: 0
  sequence_length: ${world_model.max_blocks}
  resume: False # run prefix on bucket or False. Loads full checkpoint

cloud:
  region_name: "us-east-1"
  bucket_name: "brawl-stars-iris"
  instance_id: "i-0e9cb879b7a6f87c7"
  key_file: "C:\\Users\\Mykhailo_Tkachuk\\keypair1.pem"
  log_metrics: "logs/metrics.json"  # used for logging
  log_reconstruction: "logs/reconstruction.jpg"  # used for logging

training:
  should: True
  on_cloud: True
  epochs_per_job: 1 # number of epochs to be run per job submission
  learning_rate: 1e-3
  sampling_weights: [0.125, 0.125, 0.25, 0.5]
  world_model:
    batch_num_samples: 24 # rtx3090
    grad_acc_steps: 6
    agc_lambda: 0.1
    max_grad_norm: 10.0
    weight_decay: 0.0
    start_after_epochs: 99999
    steps_per_epoch: 200
    lambda_: 0.6
    gamma: 0.95